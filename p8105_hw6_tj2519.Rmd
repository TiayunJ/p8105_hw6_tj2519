---
title: "p8105_hw6_tj2519"
output: github_document
date: "2023-11-29"
---

```{r}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(mgcv)

```

# Problem 2
## Initial setup (load the dataset) and create a bootstrap function
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())

boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

bootboot_straps = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(df) boot_sample(weather_df))
  )

```


## Run Linear Regression to the samples and calculate the log(b1*b2) and r^2 for each bootstrap sample
```{r}
bootboot_straps_results =
  bootboot_straps %>% 
  mutate(
    models = map(strap_sample, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map(models, broom::tidy),
    r_sq = map(models, broom::glance),
    log_value = map_dbl(results, ~log(.x[[2]][[2]] * .x[[2]][[3]]))) %>% 
  mutate(r_sq = map(r_sq, ~ .x %>% select(r.squared))) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results, r_sq) %>% 
  janitor::clean_names()
  
```

## Plot the estimate distributions (r^2 and log(beta1*beta2))
```{r}
bootboot_straps_results %>% 
  ggplot(aes(x = r_squared)) + 
  geom_density() +
  labs(title = "Distribution of r_squared Across the Samples")


bootboot_straps_results %>% 
  ggplot(aes(x = log_value)) + 
  geom_density() +
  labs(title = "Distribution of log(beta1*beta2) Across the Samples")
  
```
From the density plot showing the distribution of r^2, it was noticed that the most frequent r^2 appears around 0.92, and the shape is left-skewed (but roughly normal). r^2 = 0.92 It means that 92% of the variance in tmax is explained by tmin. As there are NaNs values in log(beta1*beta2) because the value of beta1*beta2 could be negative, and log calcumation could not take negtative value. The density plot of the remaining log_values is left skewed and the most frequent value of log(beta1*beta2) appears to be around -5.6. 


## Compute 95% CI for r^2 and log(beta1*beta2)
```{r}
bootboot_straps_results %>% 
  summarize(r_sq_ci_lower = quantile(r_squared, 0.025),
         r_sq_ci_upper = quantile(r_squared, 0.975),
         log_ci_lower = quantile(log_value, 0.025, na.rm = TRUE),
         log_ci_upper = quantile(log_value, 0.975, na.rm = TRUE)) %>% 
  knitr::kable()
```



# Problem 3
## Load the dataset and clean it, drop any NA values, so it would be easier in later building regression model parts. Also, I recoded certain variables and transform them into factors.
```{r}
problem3_df = 
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(babysex = recode(babysex, `1` = "male",
                          `2` = "female"),
         frace = recode(frace, `1` = "White", 
                        `2` = "Black",
                        `3` = "Asian",
                        `4` = "Puerto Rican",
                        `8` = "Other",
                        `9` = "Unknown"),
         mrace = recode(frace, `1` = "White", 
                        `2` = "Black",
                        `3` = "Asian",
                        `4` = "Puerto Rican",
                        `8` = "Other"),
         malform = recode(malform, `0` = "absent",
                          `1` = "present"),
         babysex = fct_relevel(babysex, c("male", "female")),
         frace = fct_infreq(frace),
         mrace = fct_infreq(mrace),
         malform = fct_relevel(malform, c("absent", "present")),
         ) 
  ?
```

## Create own model using stepwise method. 
### In this method, I used 'step' function in R. By using the stepwise method, the algorithm would build a linear regression model based on all the variables available in the dataset. By default, step function build the final model based on both the forward (start with intercept only) and backward method (start with all the covariates), till the default criterion - AIC value of the model could not be improved. Also write a function to create this model.
```{r}
crude_model = lm(bwt ~ ., data = problem3_df)
final_model = step(crude_model)

model_results = summary(final_model) %>% 
    broom::tidy()

own_model_function = function(data){
  step(lm(bwt ~ ., data = data), direction = "both")
}

```


## Plot with residual and prediction based on the created linear model with the outcome being birthweight
```{r}
problem3_df %>% 
  modelr::add_residuals(final_model) %>% 
  modelr::add_predictions(final_model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  labs(x = "fitted value",
       y = "residuals",
       title = "The Scatterplot plotting model residuals against fitted values")
```




## Run Linear regression with length at birth and gestational age as predictors (main effects only), and the other regression using head circumference, length, sex, and all interactions (including the three-way interaction) between these.
```{r}
model_1 = lm(bwt ~ blength + gaweeks, data = problem3_df) %>% 
  broom::tidy()
  
model_2 = lm(bwt ~ bhead * blength * babysex, data = problem3_df) %>% 
  broom::tidy()

```


## Cross-validation and compare the models using RMSE in each model
```{r}
cv_df = 
  crossv_mc(problem3_df, 50)

comparison = 
cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    own_mod  = map(train, own_model_function),
    model_1 = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model_2 = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))) %>% 
  mutate(
    rmse_own = map2_dbl(own_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_1 = map2_dbl(model_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_2 = map2_dbl(model_2, test, \(mod, df) rmse(model = mod, data = df)))
  

comparison  %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```
The RMSE indicates that the own model has the smallest RMSE, while the model_1 containing length at birth and gestational age as predictors (main effects only) has the highest RMSE, the RMSE of model_2 using head circumference, length, sex, and all interactions (including the three-way interaction) between these is between the own model and model_1. Among the three models, the RMSE of model_1 is the most spreaded.




